{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in /opt/anaconda3/lib/python3.9/site-packages (4.7.0.72)\n",
      "Requirement already satisfied: numpy>=1.19.3 in /opt/anaconda3/lib/python3.9/site-packages (from opencv-python) (1.23.5)\n"
     ]
    }
   ],
   "source": [
    "!pip install opencv-python\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "from tensorflow import keras\n",
    "import tensorflow.keras.layers as k\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator, load_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=64x64 at 0x299905D1490>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_img(r\"C:\\Users\\cell_images\\Not Healthy\",target_size=(64,64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['KERAS_BACKEND'] = 'tensorflow'\n",
    "np.random.seed(312)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_dir = r\"C:\\Users\\Deep Learning\\cell_images\"\n",
    "size = 64\n",
    "dataset = []\n",
    "label = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████| 13780/13780 [01:10<00:00, 196.43it/s]\n"
     ]
    }
   ],
   "source": [
    "parasitized_img = os.listdir(image_dir+\"\\\\Not Healthy\")\n",
    "\n",
    "for i,img_name in enumerate(tqdm(parasitized_img)):\n",
    "    if(img_name.split('.')[1] == 'png'):\n",
    "        image = cv2.imread(image_dir + \"\\\\Not Healthy\\\\\" + img_name)\n",
    "        image = Image.fromarray(image,'RGB')\n",
    "        image = image.resize((size , size))\n",
    "        \n",
    "        dataset.append(np.array(image))\n",
    "        label.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████| 13780/13780 [01:00<00:00, 227.20it/s]\n"
     ]
    }
   ],
   "source": [
    "uninfected_img = os.listdir(image_dir+\"\\\\Healthy\")\n",
    "\n",
    "for i,img_name in enumerate(tqdm(uninfected_img)):\n",
    "    if(img_name.split('.')[1] == 'png'):\n",
    "        image = cv2.imread(image_dir + \"\\\\Healthy\\\\\" + img_name)\n",
    "        image = Image.fromarray(image,'RGB')\n",
    "        image = image.resize((size , size))\n",
    "        \n",
    "        dataset.append(np.array(image))\n",
    "        label.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "xtrain,xtest,ytrain,ytest = train_test_split(dataset,to_categorical(np.array(label)),test_size = 0.2 ,random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "Input_shape = (size,size,3)\n",
    "\n",
    "inp = k.Input(shape = Input_shape)\n",
    "\n",
    "conv1 = k.Conv2D(32,kernel_size = (3,3),activation = \"relu\",padding=\"same\")(inp)\n",
    "pool1 = k.MaxPool2D(pool_size = (2,2))(conv1)\n",
    "norm1 = k.BatchNormalization(axis = -1)(pool1)\n",
    "drop1 = k.Dropout(rate = 0.2)(norm1)\n",
    "\n",
    "conv2 = k.Conv2D(32,kernel_size = (3,3),activation = \"relu\",padding=\"same\")(drop1)\n",
    "pool2 = k.MaxPool2D(pool_size = (2,2))(conv2)\n",
    "norm2 = k.BatchNormalization(axis = -1)(pool2)\n",
    "drop2 = k.Dropout(rate = 0.2)(norm2)\n",
    "\n",
    "conv3 = k.Conv2D(32,kernel_size = (3,3),activation = \"relu\",padding=\"same\")(drop2)\n",
    "pool3 = k.MaxPool2D(pool_size = (2,2))(conv3)\n",
    "norm3 = k.BatchNormalization(axis = -1)(pool3)\n",
    "drop3 = k.Dropout(rate = 0.2)(norm3)\n",
    "\n",
    "flat = k.Flatten()(drop3)\n",
    "\n",
    "hidden1 = k.Dense(512,activation=\"relu\")(flat)\n",
    "norm3   = k.BatchNormalization(axis=-1)(hidden1)\n",
    "drop3   = k.Dropout(rate=0.2)(norm3)\n",
    "\n",
    "hidden2 = k.Dense(256,activation=\"relu\")(drop3)\n",
    "norm4   = k.BatchNormalization(axis=-1)(hidden2)\n",
    "drop4   = k.Dropout(rate=0.2)(norm4)\n",
    "\n",
    "out = k.Dense(2, activation='sigmoid')(drop4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         [(None, 64, 64, 3)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 64, 64, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 32, 32, 32)        128       \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 32, 32, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 16, 16, 32)        128       \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 16, 16, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 8, 8, 32)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 8, 8, 32)          128       \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 8, 8, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 512)               1049088   \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "batch_normalization_11 (Batc (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 2)                 514       \n",
      "=================================================================\n",
      "Total params: 1,203,778\n",
      "Trainable params: 1,202,050\n",
      "Non-trainable params: 1,728\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = keras.Model(inputs = inp , outputs = out)\n",
    "model.compile(optimizer = 'adam',loss='categorical_crossentropy',metrics = ['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "311/311 [==============================] - 47s 149ms/step - loss: 0.5126 - accuracy: 0.7714 - val_loss: 0.8871 - val_accuracy: 0.8190\n",
      "Epoch 2/10\n",
      "311/311 [==============================] - 45s 144ms/step - loss: 0.2238 - accuracy: 0.9202 - val_loss: 0.5353 - val_accuracy: 0.8676\n",
      "Epoch 3/10\n",
      "311/311 [==============================] - 47s 151ms/step - loss: 0.1783 - accuracy: 0.9371 - val_loss: 0.2602 - val_accuracy: 0.9147\n",
      "Epoch 4/10\n",
      "311/311 [==============================] - 44s 141ms/step - loss: 0.1567 - accuracy: 0.9461 - val_loss: 0.2629 - val_accuracy: 0.9265\n",
      "Epoch 5/10\n",
      "311/311 [==============================] - 47s 151ms/step - loss: 0.1419 - accuracy: 0.9508 - val_loss: 0.1702 - val_accuracy: 0.9410\n",
      "Epoch 6/10\n",
      "311/311 [==============================] - 45s 143ms/step - loss: 0.1324 - accuracy: 0.9527 - val_loss: 0.1626 - val_accuracy: 0.9401\n",
      "Epoch 7/10\n",
      "311/311 [==============================] - 44s 143ms/step - loss: 0.1226 - accuracy: 0.9563 - val_loss: 0.1381 - val_accuracy: 0.9537\n",
      "Epoch 8/10\n",
      "311/311 [==============================] - 44s 140ms/step - loss: 0.1168 - accuracy: 0.9581 - val_loss: 0.1305 - val_accuracy: 0.9574\n",
      "Epoch 9/10\n",
      "311/311 [==============================] - 44s 143ms/step - loss: 0.1088 - accuracy: 0.9622 - val_loss: 0.1320 - val_accuracy: 0.9587\n",
      "Epoch 10/10\n",
      "311/311 [==============================] - 44s 140ms/step - loss: 0.1034 - accuracy: 0.9626 - val_loss: 0.1443 - val_accuracy: 0.9492\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(np.array(xtrain),ytrain,\n",
    "                   batch_size= 64,verbose=1,epochs = 10,validation_split=0.1,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "173/173 [==============================] - 3s 17ms/step - loss: 0.1550 - accuracy: 0.9452\n",
      "Test accuracy: 94.52%\n"
     ]
    }
   ],
   "source": [
    "print(\"Test accuracy: {:.2f}%\".format(model.evaluate(np.array(xtest),np.array(ytest))[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(r\"C:\\Users\\Deep Learning\\malaria_cell_detection.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
